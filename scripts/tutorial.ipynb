{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "To store dissimilarity matrices or embeddings, an instance of the class `Representation` is used.   \n",
    "Please put your dissimilarity matrices or embeddings into the variables `sim_mat` or `embedding` in this instance.   \n",
    "\n",
    "## Load data\n",
    "You can select the data from the following options:   \n",
    "1. `color`: Human similarity judgements of 93 colors for 5 groups of participants from the data used in Kawakita et al., 2023, PsyArxiv   \n",
    "2. `THINGS` : Human similarity judgments of 1854 objects for 4 groups of participants from the THINGS data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "\n",
    "# select data : \"THINGS\", \"color\"\n",
    "# data_select = \"color\"\n",
    "data_select = \"THINGS\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.1 `color`\n",
    "In this case, we directly assign the dissimilarity matrices of 93 colors to the instance `Representation`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create \"Representation\" instance\n",
    "if data_select == \"color\":\n",
    "    n_representations = 4  # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 5 is the maximum for this data.\n",
    "    metric = \"euclidean\"  # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    data_path = \"../data/color/num_groups_5_seed_0_fill_val_3.5.pickle\"\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pkl.load(f)\n",
    "    sim_mat_list = data[\"group_ave_mat\"]\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\" # \"name\" will be used as a filename for saving the results\n",
    "        sim_mat = sim_mat_list[i] # the dissimilarity matrix of the i-th group\n",
    "        # make an instance \"Representation\" with settings \n",
    "        representation = Representation(\n",
    "            name=name, \n",
    "            metric=metric,\n",
    "            sim_mat=sim_mat,  #: np.ndarray\n",
    "            embedding=None,  #: np.ndarray \n",
    "            get_embedding=True,  # If true, the embeddings are computed from the dissimilarity matrix automatically using the MDS function. Default is False. \n",
    "            MDS_dim=3,  # If \"get embedding\" is True, please set the dimensions of the embeddings.\n",
    "            object_labels=None,\n",
    "            category_name_list=None,\n",
    "            num_category_list=None,\n",
    "            category_idx_list=None,\n",
    "            func_for_sort_sim_mat=None,\n",
    "       ) \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset No.2 `THINGS`\n",
    "In this case, we assign the embeddings of 1,854 natural objects to the instance `Representation`.   \n",
    "This instance compute the dissimilarity matrices from the embeddings based on `metric`.  \n",
    "\n",
    "In addition to the object labels, this dataset includes coarse category labels for each object.   \n",
    "These coarse category labels are used for the evaluation and visualization of alignment.  \n",
    "The category information is stored in the variables `category_idx_list` and `category_name_list`.  \n",
    "For your application, please put category information in these variables.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\":\n",
    "    # define the coarce category labels\n",
    "    category_mat = pd.read_csv(\"../data/THINGS/category_mat_manual_preprocessed.csv\", sep=\",\", index_col=0)\n",
    "    \n",
    "    # calculate the parameters for the coarce category labels\n",
    "    # Please prepare equivalent parameters when using other datasets.\n",
    "    from src.utils.utils_functions import get_category_data, sort_matrix_with_categories  # get_category_data and sort_matrix_with_categories are functions specialied for this dataset\n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat)\n",
    "    \n",
    "    n_representations = 3  # Set the number of the instanses of \"Representation\". This number must be equal to or less than the number of the groups. 4 is the maximum for this data.\n",
    "    metric = \"euclidean\"  # Please set the metric that can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    \n",
    "    for i in range(n_representations):\n",
    "        name = f\"Group{i+1}\"  # the name of the representation\n",
    "        embedding = np.load(f\"../data/THINGS/THINGS_embedding_Group{i+1}.npy\")[0]  # the dissimilarity matrix will be computed with this embedding based on the metric\n",
    "        \n",
    "        representation = Representation(\n",
    "            name=name,\n",
    "            embedding=embedding,\n",
    "            metric=metric,\n",
    "            get_embedding=False,  # If there is the embeddings, plese set this variable \"False\".\n",
    "            object_labels=object_labels,  # the labels of the objects\n",
    "            category_name_list=category_name_list,  # the names of the categories\n",
    "            category_idx_list=category_idx_list,  # the indexes of the categories. This is used for the evaluation and the visualization of the unsuperivsed alignment.\n",
    "            num_category_list=num_category_list, \n",
    "            func_for_sort_sim_mat=sort_matrix_with_categories,\n",
    "        )\n",
    "        \n",
    "        representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "Second, you need to set the parameters for the optimization of GWOT.    \n",
    "For most of the parameters, you can start with the default values.   \n",
    "However, there are some essential parameters that you need to check for your original applications.  \n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list` : The range of the values of epsilon for entropic GWOT.   \n",
    "If epsilon is not in appropriate ranges (if it is too low), the optimization may not work properly.   \n",
    "Although the algorithm will find good epsilon values after many trials, it is a good practice to narrow down the range beforehand.   \n",
    "\n",
    "`num_trial` : The number of trials to test epsilon values from the specified range.   \n",
    "This number directly determines the quality of the unsupervised alignment.   \n",
    "You should set this number high enough to find good local minima.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Most important parameters\n",
    "# Set the range of the epsilon\n",
    "# set the minimum value and maximum value for \"tpe\" sampler\n",
    "# for \"grid\" or \"random\" sampler, you can also set the step size    \n",
    "if data_select == \"color\":\n",
    "    eps_list_tutorial = [0.02, 0.2]\n",
    "    device = \"cpu\"\n",
    "    to_types = \"numpy\"\n",
    "\n",
    "if data_select == \"THINGS\":\n",
    "    eps_list_tutorial = [1, 10]\n",
    "    device = \"cpu\" # \"cuda\"\n",
    "    to_types = \"numpy\" # \"torch\"\n",
    "\n",
    "# whether epsilon is sampled at log scale or not\n",
    "eps_log = True\n",
    "\n",
    "# set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "num_trial = 4\n",
    "\n",
    "### Set the parameters for optimization\n",
    "# initialization of transportation plan\n",
    "# \"uniform\": uniform matrix, \"diag\": diagonal matrix, \"random\": random matrix\n",
    "# Select multiple options was deprecated.\n",
    "init_mat_plan = \"random\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The setting of device (cuda or cpu)\n",
    "`cuda` : For using GPU, the `device` and `to_types` needs to be set to `cuda` and `torch`, respectively. You can choose to use multiple GPUs by setting `multi_gpu` to True.\n",
    "\n",
    "`cpu` : For using numpy, the device needs to be set to `cpu` and to_types needs to be set to `numpy`. The `multi_gpu` option is not available for numpy, so `multi_gpu = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    sinkhorn_method = \"sinkhorn_log\" # please choose the method of sinkhorn implemented by POT (URL : https://pythonot.github.io/gen_modules/ot.bregman.html#id87). For using GPU, \"sinkhorn_log\" is recommended.\n",
    "    data_type= \"float\"\n",
    "    multi_gpu = False # This parameter is only designed for \"torch\". # \"True\" : all the GPU installed in your environment are used, \"list (e.g.[0,2,3])\"\" : cuda:0,2,3, and \"False\" : single gpu will be used.\n",
    "\n",
    "elif device == \"cpu\":\n",
    "    sinkhorn_method = \"sinkhorn\"\n",
    "    data_type = \"double\"\n",
    "    multi_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If user wants to use some user-defined init matrices...\n",
    "For ”user_define”, note that all the initialization plans need to be written in Numpy even when PyTorch is used for the optimization.  \n",
    "You can define a single or multiple plans before the optimization starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if init_mat_plan == \"user_define\":\n",
    "    import ot\n",
    "    size = representation.sim_mat.shape[0]\n",
    "    user_define_init_mat_list = [np.outer(ot.unif(size), ot.unif(size))] # This is uniform tranportation plan but you can change it to any other plan\n",
    "    \n",
    "else:\n",
    "    user_define_init_mat_list = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(    \n",
    "    eps_list = eps_list_tutorial,  # [1, 10] for THINGS data, [0.02, 0.2] for colors data\n",
    "    eps_log = eps_log,  # whether epsilon is sampled at log scale or not\n",
    "    num_trial = num_trial,  # set the number of trials, i.e., the number of epsilon values evaluated in optimization. default : 4\n",
    "    sinkhorn_method=sinkhorn_method, \n",
    "    \n",
    "    ### Set the device (\"cuda\" or \"cpu\") and variable type (\"torch\" or \"numpy\")\n",
    "    to_types = to_types,  # user can choose \"numpy\" or \"torch\". please set \"torch\" if one wants to use GPU.\n",
    "    device = device,  # \"cuda\" or \"cpu\"; for numpy, only \"cpu\" can be used. \n",
    "    data_type = data_type,  # user can define the dtypes both for numpy and torch, \"float(=float32)\" or \"double(=float64)\". For using GPU with \"sinkhorn\", double is storongly recommended.\n",
    "    \n",
    "    ### Parallel Computation (requires n_jobs > 1, available both for numpy and torch)\n",
    "    n_jobs = 3,  # n_jobs : the number of worker to compute. if n_jobs = 1, normal computation will start. \"Multithread\" is used for Parallel computation.\n",
    "    multi_gpu = multi_gpu,  # In the situation like n_jobs = 2 and multi_gpu = [0, 1, 2, 3], the first two group will be computed by GPU:0 and GPU:1, and the second two group will be computed by GPU:2 and GPU:3.\n",
    "    \n",
    "    ### Set the db_params to create database URL to store the optimization results (either MySQL or SQLite. For using MySQL, some additional setting beforehand will be needed).  \n",
    "    # The database URL in sqlalchemy is like \"dialect+driver://username:password@host:port/database\". See the following page for details. https://docs.sqlalchemy.org/en/20/core/engines.html\n",
    "    # If you want to use SQLite, it\"s enough to set \"db_params={\"drivername\": \"sqlite\"}\".\n",
    "    # This package generates 1 database per each study.\n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    # db_params={\"drivername\": \"mysql+pymysql\", \"username\": \"root\", \"password\": \"****\", \"host\": \"localhost\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # \"uniform\": uniform matrix, \"diag\": diagonal matrix, \"random\": random matrix\n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    # user-defined initialization plans\n",
    "    user_define_init_mat_list = user_define_init_mat_list,\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # n_iter : the number of random initial matrices for \"random\" or \"permutation\" options：default: 1\n",
    "    # max_iter : the maximum number of iteration for GW optimization: default: 200\n",
    "    n_iter = 1,\n",
    "    max_iter = 200,\n",
    "    \n",
    "    ### choose sampler implemented by Optuna\n",
    "    # 1. \"random\": randomly select epsilon between the range of epsilon\n",
    "    # 2. \"grid\": grid search between the range of epsilon\n",
    "    # 3. \"tpe\": Bayesian sampling\n",
    "    sampler_name = \"tpe\",\n",
    "    \n",
    "    ### choose pruner\n",
    "    # 1. \"median\": Pruning if the score is below the past median at a certain point in time  \n",
    "    #     n_startup_trials: Do not activate the pruner until this number of trials has finished  \n",
    "    #     n_warmup_steps: Do not activate the pruner for each trial below this step  \n",
    "        \n",
    "    # 2. \"hyperband\": Use multiple SuccessiveHalvingPrunerd that gradually longer pruning decision periods and that gradually stricter criteria  \n",
    "    #     min_resource: Do not activate the pruner for each trial below this step  \n",
    "    #     reduction_factor: How often to check for pruning. Smaller values result in more frequent pruning checks. Between 2 to 6.  \n",
    "        \n",
    "    # 3. \"nop\": no pruning\n",
    "    pruner_name = \"hyperband\",\n",
    "    pruner_params = {\"n_startup_trials\": 1, \n",
    "                     \"n_warmup_steps\": 2, \n",
    "                     \"min_resource\": 2, \n",
    "                     \"reduction_factor\" : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Gromov-Wasserstein Optimal Transport (GWOT) between Representations\n",
    "Third, you perform GWOT between the instanses of \"Representation\", by using the class `AlignRepresentations`.  \n",
    "This class has methods for the optimization of entropic Gromov-Wasserstein distance, and the evaluation of the GWOT (Step 4).  \n",
    "This class also has a method to perform conventional Representation Similarity Analysis (RSA).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Directory for saving the results of GWOT\n",
    "\n",
    "Here is the directory structure to save the results below.  \n",
    "\n",
    "```\n",
    "    main_results_dir (= data_name (e.g. `THINGS`)) /\n",
    "        ├─ data_name + pair_name (e.g. `THINGS_Group1_vs_Group2`) /\n",
    "        │    ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │        ├─ figure /\n",
    "        │        │   ├─ some figures (e.g. acc_gwd_eps.png)\n",
    "        │        ├─ data /\n",
    "        │        │   ├─ OT.npy (numpy) or OT.pt (torch)\n",
    "        │        │   \n",
    "        │        ├─ database (if using sqlite; e.g. `THINGS_Group1_vs_Group2_random.db`)\n",
    "        │\n",
    "        ├─ visualize_embedding/ \n",
    "        │    ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │            ├─  some figures(e.g. `Aligned_embedding.png`; made by running `align_representation.visualize_embedding`. Please see the bottom of this notebook) \n",
    "        │\n",
    "        ├─ individual_sim_mat (e.g. `RDM_Group1.png`) /\n",
    "                ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "                        ├─  some figures(e.g. `RDM_Group1.png`) \n",
    "        \n",
    "``` \n",
    "\n",
    "- This folder structure will be automatically made in the process of GWOT optimization.\n",
    "- You can provide the names of the save folders by changing the following variables: `main_result_dir`,  `data_name`, and `pair_name`(defined by the two `representations.name`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Choose pairs of representations for GWOT optimization\n",
    "By default, GWOT will be performed for all the pairs of given representations.   \n",
    "You can specify particular pairs that you want to compute as follows.   \n",
    "Also, you can also customize the epsilon range for particular pairs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default setting (compute all the pairs if `pair_computed` is None)\n",
    "pairs_computed = None\n",
    "\n",
    "# If you wish to compute only partiuclar pairs or all the pairs which have one partiuclar representation, you can specify them as follows.\n",
    "# In this example below,  \n",
    "# \"Group1\": all the pairs with \"Group1\"  \n",
    "# \"Group2_vs_Group4\": only the pair named \"Group2_vs_Group4\"\n",
    "# Please use \"_vs_\" between the representations' names for a single pair. \n",
    "# And please also keep in mind that the name of each pair will be made by the order of `representations_list`, which means \"Group4_vs_Group2\" can\"t be accepted.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"]\n",
    "\n",
    "# Default setting (use the same epsilon range for all the pairs)\n",
    "specific_eps_list = None\n",
    "\n",
    "# If you wish to change the epsilon range for particular pairs, you can specify them as follows.\n",
    "# specific_eps_list = {\"Group1\": [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,   \n",
    "   \n",
    "    # pairs_computed : user can limit the pairs here\n",
    "    pairs_computed = pairs_computed,\n",
    "   \n",
    "    # specific_eps_list : user can define a specific range of epsilon for some pairs.\n",
    "    specific_eps_list = specific_eps_list,\n",
    "   \n",
    "    # histogram matching : this will adjust the histogram of target to that of source.\n",
    "    histogram_matching=False,\n",
    "\n",
    "    # metric : The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    metric=\"euclidean\", \n",
    "\n",
    "    # main_results_dir : folder or file name when saving the result\n",
    "    main_results_dir = \"../results/\" + data_select,\n",
    "   \n",
    "    # data_name : Please rewrite this name if users want to use their own data.\n",
    "    data_name = data_select,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you want to re-run the optimization process for specific pairs only\n",
    "You can change the specific pairs to be computed by setting `pair_computed` as follows.   \n",
    "You can also change the epsilon range `specific_eps_list` as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User can only re-run the optimization for specific pairs by using `set_pair_computed`.\n",
    "\n",
    "# pairs_computed = [\"Group1\", \"Group2_vs_Group4\"]\n",
    "# align_representation.set_pair_computed(pairs_computed)\n",
    "\n",
    "# Also, user can also re-define the epsilon range for some pairs by using `set_specific_eps_list`. The rest of them will be computed with `config.eps_list`. \n",
    "# If `specific_only` is True (default is False), only these pairs will be computed and the rest of them were skipped.\n",
    "\n",
    "# specific_eps_list = {\"Group1\": [0.02, 0.1], \"Group2_vs_Group4\":[0.1, 0.2]}\n",
    "# align_representation.set_specific_eps_list(specific_eps_list, specific_only=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualizationConfig\n",
    "You can set the parameters for visualizaing the results of the GWOT optimization.   \n",
    "Here, we introduce all the parameters that will be used for this instance.   \n",
    "Some of them may be modified later for each dataset.   \n",
    "Please keep in mind you can also get the raw results data if you want to customize the figures by yourself.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_config = VisualizationConfig(\n",
    "    ### If you want to save the figure only, and don\"t show them, please set show_figure = False.\n",
    "    show_figure = True,\n",
    "    \n",
    "    ### Please set the parameters of the figure's appearance. The figure is drawn based on \"matplotlib.pyplot\"\n",
    "    fig_ext=\"png\",\n",
    "    figsize=(8, 6),\n",
    "    font=\"DejaVu Sans\",\n",
    "    cbar_label_size=15,\n",
    "    cbar_ticks_size=15,\n",
    "    cbar_format=None,\n",
    "    cbar_label=None,\n",
    "    xticks_size=20,\n",
    "    yticks_size=20,\n",
    "    xticks_rotation=90,\n",
    "    yticks_rotation=0,\n",
    "    tick_format=\"%.2f\",\n",
    "    title_size=20,\n",
    "    legend_size=5,\n",
    "    xlabel=None,\n",
    "    xlabel_size=15,\n",
    "    ylabel=None,\n",
    "    ylabel_size=15,\n",
    "    zlabel=None,\n",
    "    zlabel_size=15,\n",
    "    color_labels=None,\n",
    "    color_hue=None,\n",
    "    markers_list=None,\n",
    "    marker_size=30,\n",
    "    color = \"C0\",\n",
    "    cmap = \"cividis\",\n",
    "    \n",
    "    ### Set ticks of the object label or the coarce category labels.\n",
    "    # If both are False, no tick will be shown in the figure.\n",
    "    ot_object_tick=False,\n",
    "    ot_category_tick=False,\n",
    "    \n",
    "    ### Set the parameters for showing the boundary of the coarce category labels in the OT figure if the dataset have them. \n",
    "    # If not, please set draw_category_line = False.\n",
    "    # Note that please set ot_category_tick = True when drawing the category line.\n",
    "    draw_category_line=False,\n",
    "    category_line_color=\"C2\",\n",
    "    category_line_alpha=0.2,\n",
    "    category_line_style=\"dashed\",\n",
    "    \n",
    "    \n",
    "    ### From here below, user can define the parameters using for evaluation figure after alignment computation is done.\n",
    "    # It is not necessary to set them here becuase we prepared \"set_params\" to add or re-define the parameters for making the figures. \n",
    "    # So, all the parameters below will be introduced after the alignment block.\n",
    "    plot_eps_log=eps_log,\n",
    "    lim_eps=None,\n",
    "    lim_gwd=None,\n",
    "    lim_acc=None,  \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset without category information\n",
    "if data_select == \"color\":\n",
    "    sim_mat_format = \"default\"\n",
    "    \n",
    "    visualize_config = VisualizationConfig(\n",
    "        fig_ext = \"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(8, 6), \n",
    "        font=\"DejaVu Sans\",\n",
    "        title_size = 15,\n",
    "        cmap = \"rocket_r\",\n",
    "        ot_object_tick=True,\n",
    "        plot_eps_log=eps_log,\n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color=\"C0\")\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format = sim_mat_format, \n",
    "        visualization_config = visualize_config,\n",
    "        visualization_config_hist = visualize_hist,\n",
    "        show_distribution=False, # if True, the histogram figure of the sim_mat will be shown. visualization_config_hist will be used for adjusting this figure.\n",
    "        ticks = None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset with category information\n",
    "if data_select == \"THINGS\":\n",
    "    sim_mat_format = \"sorted\"\n",
    "    visualize_config = VisualizationConfig(\n",
    "        show_figure = True,\n",
    "        fig_ext=\"svg\", # you can also use \"png\" or \"pdf\", and so on. Default is \"png\".\n",
    "        figsize=(8, 6), \n",
    "        title_size = 15, \n",
    "        cmap = \"rocket_r\",\n",
    "        cbar_ticks_size=20,\n",
    "        \n",
    "        ot_object_tick=False,\n",
    "        ot_category_tick=False,\n",
    "        \n",
    "        xticks_size=10,\n",
    "        yticks_size=10,\n",
    "        \n",
    "        # Note that please set ot_category_tick = True when drawing the category line.\n",
    "        draw_category_line=False,\n",
    "        category_line_color=\"black\",\n",
    "        category_line_alpha=0.5,\n",
    "        category_line_style=\"dashed\",\n",
    "    )\n",
    "    \n",
    "    visualize_hist = VisualizationConfig(figsize=(8, 6), color=\"C0\")\n",
    "    \n",
    "    sim_mat = align_representation.show_sim_mat(\n",
    "        sim_mat_format=sim_mat_format, \n",
    "        visualization_config=visualize_config,\n",
    "        visualization_config_hist=visualize_hist,\n",
    "        fig_dir=None, # If fig_dir is None, the figure will be saved in the \"individual_figure\" directly under the main_results_folder.\n",
    "        show_distribution=False,\n",
    "        ticks=\"category\",\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)\n",
    "This performs a conventional representation similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# The result of RSA for each pair will be stored in align_representation.RSA_corr\n",
    "align_representation.RSA_get_corr(metric = \"pearson\")\n",
    "\n",
    "# print(align_representation.RSA_corr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GWOT\n",
    "The optimization results are saved in the folder named \"align_representation.data_name\" + \"representations.name\" vs \"representation.name\".  \n",
    "If you want to change the name of the saved folder, please change \"align_representation.data_name\" and \"representations.name\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. In this case, the previously calculated OT plans will be loaded.\n",
    "compute_OT = True\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GWOT is performed by appling the method `gw_alignment` to the instance of `AlignRepresentations` class.   \n",
    "We show all the parameters to run GWOT computation as an example with `THINGS` dataset because this has category information label.   \n",
    "For the `color` dataset, we omit some parameters to specify (which are set to default values).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"THINGS\": \n",
    "    sim_mat_format = \"sorted\" # \"sorted\" : the rows and columns of the OT plans are sorted by the coarce categories. If there is no need for sorting, set it to \"default\".\n",
    "\n",
    "    visualize_config.set_params(\n",
    "        # user can re-define the parameter if necessary.        \n",
    "        xticks_rotation=0,\n",
    "        cbar_label_size=15,\n",
    "        cbar_ticks_size=15,\n",
    "        xticks_size=20,\n",
    "        yticks_size=20,\n",
    "        xlabel_size=15,\n",
    "        ylabel_size=15, \n",
    "        \n",
    "        # plot_eps_log : user can choose the scale of eps in the figure. True = log scale, False = linear scale.\n",
    "        plot_eps_log=eps_log,\n",
    "        \n",
    "        # lim_eps : define the range of eps to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_eps=None,\n",
    "        \n",
    "        # lim_gwd : define the range of GWD to show in the figure. \n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_gwd=None,\n",
    "        \n",
    "        # lim_acc : define the range of accuracy to show in the figure. the unit of accuracy is percentage. So, maximum is 100.\n",
    "        # If None, default setting of matplotlib to detect the range will be used.\n",
    "        lim_acc=[0, 100],      \n",
    "    )\n",
    "    \n",
    "    ot_list = align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        \n",
    "        ## return_data : If True, the \"OT_format\" data will be returned in `ot_list`.\n",
    "        return_data = False,\n",
    "        \n",
    "        ## return_figure : If True, figure of OT will be shown in this notebook. Figure is always saved in the \"figure\" folder.\n",
    "        return_figure = True,\n",
    "        \n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_config,\n",
    "        \n",
    "        ## show_log : if True, this will show the figures how the GWD was optimized. \n",
    "        # So, please set the parameters of them before this function starts to compute.\n",
    "        # The details of it will be explained in the next block.\n",
    "        show_log=False, \n",
    "        \n",
    "        ## fig_dir : you can define the path to which you save the figures (.png). If None, the figures will be saved in the same subfolder in \"results_dir\"\n",
    "        fig_dir=None,\n",
    "        \n",
    "        ## ticks : you can use \"objects\" or \"category\" or \"None\". Default is None.\n",
    "        ticks=\"category\", \n",
    "        \n",
    "        ## save_dataframe : if True, you can save all the computed data stored in SQlite or PyMySQL in csv format (pandas.DataFrame) in the result folder.\n",
    "        save_dataframe=False,\n",
    "        \n",
    "        ## change_sampler_seed : If True, the random seed will be changed for each pair, else, the same seed defined in the next parameter will be used.  Default is False.\n",
    "        change_sampler_seed=True, \n",
    "        \n",
    "        ## fix_sampler_seed : this seed is used mainly for random sampler and TPE samapler. you can set any int (>= 0) value for sampler\"s seed. Default is 42.\n",
    "        fix_sampler_seed = 42, \n",
    "        \n",
    "        ## parallel_method : user can change the way of parallel computation, \"multiprocess\" or \"multithread\".\n",
    "        # \"multithread\" may be effective for most case, please choose the best one for user's environment.\n",
    "        parallel_method=\"multithread\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    # user can re-define the parameter if necessary.\n",
    "    visualize_config.set_params(\n",
    "        xticks_rotation=0,\n",
    "        cbar_label_size=15,\n",
    "        cbar_ticks_size=15,\n",
    "        xticks_size=20,\n",
    "        yticks_size=20,\n",
    "        xlabel_size=15,\n",
    "        ylabel_size=15,\n",
    "        \n",
    "        cbar_format = \"%.1e\",\n",
    "    )\n",
    "    \n",
    "    sim_mat_format = \"default\"\n",
    "\n",
    "    align_representation.gw_alignment(\n",
    "        compute_OT = compute_OT,\n",
    "        delete_results = delete_results,\n",
    "        return_data = False,\n",
    "        return_figure = True,\n",
    "        OT_format = sim_mat_format,\n",
    "        visualization_config = visualize_config,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation and Visualization\n",
    "Finally, you can evaluate and visualize the unsupervise alignment of GWOT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).   \n",
    "You can re-define the parameters used for the figures after the GWOT optimization is done.  \n",
    "We show how to use the parameter setter `visualize_config.set_params` by using the `THINGS` dataset as an example.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show how the GWD was optimized (evaluation figure)\n",
    "# show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "align_representation.show_optimization_log(fig_dir=None, visualization_config=visualize_config) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan.  \n",
    "For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".   \n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.   \n",
    "For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".   \n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by setting `top_k_list`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\", return_dataframe=False)\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the category level accuracy\n",
    "When there are category labels, you can also compute the acccuracy at the category level.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data has the coarse category labels, you can observe the category level accuracy.\n",
    "# This accuracy is calculated based on the OT plan.\n",
    "if data_select == \"THINGS\":\n",
    "    align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"category\", category_mat=category_mat)\n",
    "    align_representation.plot_accuracy(eval_type = \"category\", scatter = True)\n",
    "\n",
    "    category_level_accuracy = align_representation.category_level_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using the optimized transportation plans, you can align the embeddings of each representation in a common space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to set the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that \"pair_number_list\" includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_select == \"color\":\n",
    "    file_path = \"../data/color/color_dict.csv\"\n",
    "    data_color = pd.read_csv(file_path)\n",
    "    color_labels = data_color.columns.values # Set color labels if exist\n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        fig_ext=\"svg\",\n",
    "        color_labels=color_labels, # If there is no specific color labels, please set it to \"None\". Color labels will be automatically generated in that case. \n",
    "        color_hue=None, # If \"color_labels=None\", you have the option to choose the color hue as either \"cool\", \"warm\", or \"None\".\n",
    "        figsize=(9, 9), \n",
    "        xlabel=\"PC1\", \n",
    "        ylabel=\"PC2\",\n",
    "        zlabel=\"PC3\", \n",
    "        legend_size=10,\n",
    "    )\n",
    "    \n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3, # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        method=None,\n",
    "        pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "        visualization_config=visualization_embedding\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the embeddings have more than 4 dimensions, you can use some dimensionality reduction techniques to plot them in 2D or 3D.  \n",
    "Please set `PCA`, `TSNE`, `Isomap`, or `MDS` to the `method` argument in the `visualize_embedding` function.  \n",
    "You can also pass the parameters for each dimensionality reduction technique as a dictionary to the `method_params` argument.  \n",
    "For more details, please refer to the scikit-learn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color labels and coarse category labels if exist.\n",
    "# If there are a large number of objects within each group, such as in the case of THINGS data, visualizing all the points may not be meaningful. \n",
    "# In such cases, it is necessary to specify specific coarse category labels that you would like to visualize.\n",
    "if data_select == \"THINGS\":\n",
    "    category_name_list = [\"bird\", \"insect\", \"plant\", \"clothing\",  \"furniture\", \"fruit\", \"drink\", \"vehicle\"] # please specify the categories that you would like to visualize.\n",
    "    category_mat = pd.read_csv(\"../data/THINGS/category_mat_manual_preprocessed.csv\", sep = \",\", index_col = 0)   \n",
    "    object_labels, category_idx_list, num_category_list, category_name_list = get_category_data(category_mat, category_name_list, show_numbers = True)  \n",
    "    \n",
    "    visualization_embedding = VisualizationConfig(\n",
    "        fig_ext=\"svg\",\n",
    "        figsize=(8, 8), \n",
    "        xlabel=\"PC1\",\n",
    "        ylabel=\"PC2\", \n",
    "        zlabel=\"PC3\", \n",
    "        marker_size=6,\n",
    "        legend_size=10,\n",
    "    )\n",
    "    \n",
    "    # PCA\n",
    "    # The figures made from the following code will be saved in the directory \"/main_results_dir/data_name/visualize_embedding\".\n",
    "    align_representation.visualize_embedding(\n",
    "        dim=3,  # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "        method=\"PCA\",\n",
    "        pivot=0, # the index of the target embedding space to which the other embeddings will be aligned or the \"barycenter\"\n",
    "        visualization_config=visualization_embedding,\n",
    "        category_name_list=category_name_list, \n",
    "        category_idx_list=category_idx_list, \n",
    "        num_category_list=num_category_list,\n",
    "    )\n",
    "    \n",
    "    # t-SNE\n",
    "    # align_representation.visualize_embedding(\n",
    "    #     dim=3,  # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "    #     method=\"TSNE\",\n",
    "    #     method_params={\"perplexity\": 50},\n",
    "    #     pivot=0, # the index of the target embedding space to which the other embeddings will be aligned or the \"barycenter\"\n",
    "    #     visualization_config=visualization_embedding,\n",
    "    #     category_name_list=category_name_list, \n",
    "    #     category_idx_list=category_idx_list, \n",
    "    #     num_category_list=num_category_list,\n",
    "    # )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Delete Results\n",
    "\n",
    "If you want to delete both the directory and the database where all the computation results are saved, you can use `align_representation.drop_gw_alignment_files`.  \n",
    "Please be very careful because this operation is irreversible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align_representation.drop_gw_alignment_files(drop_all=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
