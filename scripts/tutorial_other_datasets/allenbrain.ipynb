{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial for Gromov-Wassserstein unsupervised alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '../../'))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.align_representations import Representation, AlignRepresentations, OptimizationConfig, VisualizationConfig"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Prepare dissimilarity matrices or embeddings from the data\n",
    "First, you need to prepare dissimilarity matrices or embeddings from your data.  \n",
    "To store dissimilarity matrices or embeddings, an instance of the class `Representation` is used.   \n",
    "Please put your dissimilarity matrices or embeddings into the variables `sim_mat` or `embedding` in this instance.   \n",
    "\n",
    "## Load data\n",
    "`AllenBrain`: Neuropixel data recorded in the visual areas of mice from the Allen Brain Observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of representations where the instances of \"Representation\" class are included\n",
    "representations = list()\n",
    "data_select = \"AllenBrain\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset `AllenBrain`\n",
    "We treat the average spike count for `natural movie one` in the VISal and VISam of two independent pseudo-mice as an embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "for name in [\"pseudo_a_VISal\", \"pseudo_b_VISam\"]:\n",
    "    emb = np.load(f\"../../data/AllenBrain/{name}.npy\")\n",
    "    representation = Representation(\n",
    "        name=name,\n",
    "        embedding=emb,  # the dissimilarity matrix will be computed with this embedding.\n",
    "        metric=\"cosine\",\n",
    "        get_embedding=False, # If there is the embeddings, plese set this variable \"False\".\n",
    "        object_labels=np.arange(emb.shape[0]) \n",
    "    )\n",
    "    representations.append(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Set the parameters for the optimazation of GWOT\n",
    "Second, you need to set the parameters for the optimization of GWOT.    \n",
    "For most of the parameters, you can start with the default values.   \n",
    "However, there are some essential parameters that you need to check for your original applications.  \n",
    "\n",
    "## Optimization Config  \n",
    "\n",
    "#### Most important parameters to check for your application:\n",
    "`eps_list`: The range of the values of epsilon for entropic GWOT.   \n",
    "If epsilon is not in appropriate ranges (if it is too low), the optimization may not work properly.   \n",
    "Although the algorithm will find good epsilon values after many trials, it is a good practice to narrow down the range beforehand.   \n",
    "\n",
    "`num_trial`: The number of trials to test epsilon values from the specified range.   \n",
    "This number directly determines the quality of the unsupervised alignment.   \n",
    "You should set this number high enough to find good local minima. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list_tutorial = [1e-4, 1e-1]\n",
    "device = 'cpu'\n",
    "to_types = 'numpy'\n",
    "multi_gpu = False\n",
    "\n",
    "eps_log = True\n",
    "num_trial = 4\n",
    "init_mat_plan = \"random\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OptimizationConfig(    \n",
    "    eps_list = eps_list_tutorial,\n",
    "    eps_log = eps_log,\n",
    "    num_trial = num_trial,\n",
    "    sinkhorn_method='sinkhorn_log',\n",
    "    \n",
    "    ### Set the device ('cuda' or 'cpu') and variable type ('torch' or 'numpy')\n",
    "    to_types = to_types,\n",
    "    device = device,\n",
    "    data_type = \"double\", \n",
    "    \n",
    "    n_jobs = 1,\n",
    "    multi_gpu = multi_gpu, \n",
    "    db_params={\"drivername\": \"sqlite\"},\n",
    "    \n",
    "    ### Set the parameters for optimization\n",
    "    # 'uniform': uniform matrix, 'diag': diagonal matrix', random': random matrix\n",
    "    init_mat_plan = init_mat_plan,\n",
    "    \n",
    "    # user-defined initialization plans\n",
    "    user_define_init_mat_list = None,\n",
    "\n",
    "    n_iter = 1,\n",
    "    max_iter = 500,\n",
    "    \n",
    "    sampler_name = 'tpe',\n",
    "    pruner_name = 'hyperband',\n",
    "    pruner_params = {'n_startup_trials': 1, \n",
    "                     'n_warmup_steps': 2, \n",
    "                     'min_resource': 2, \n",
    "                     'reduction_factor' : 3\n",
    "                    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Gromov-Wasserstein Optimal Transport (GWOT) between Representations\n",
    "Third, you perform GWOT between the instanses of \"Representation\", by using the class `AlignRepresentations`.  \n",
    "This class has methods for the optimization of entropic Gromov-Wasserstein distance, and the evaluation of the GWOT (Step 4).  \n",
    "This class also has a method to perform conventional Representation Similarity Analysis (RSA).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## Directory for saving the results of GWOT\n",
    "\n",
    "Here is the directory structure to save the results below.  \n",
    "\n",
    "```\n",
    "    main_results_dir (= data_name (e.g. `THINGS`)) /\n",
    "        ├─ data_name + pair_name (e.g. `THINGS_Group1_vs_Group2`) /\n",
    "        │    ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │        ├─ figure /\n",
    "        │        │   ├─ some figures (e.g. acc_gwd_eps.png)\n",
    "        │        ├─ data /\n",
    "        │        │   ├─ OT.npy (numpy) or OT.pt (torch)\n",
    "        │        │   \n",
    "        │        ├─ database (if using sqlite; e.g. `THINGS_Group1_vs_Group2_random.db`)\n",
    "        │\n",
    "        ├─ visualize_embedding/ \n",
    "        │    ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "        │            ├─  some figures(e.g. `Aligned_embedding.png`; made by running `align_representation.visualize_embedding`. Please see the bottom of this notebook) \n",
    "        │\n",
    "        ├─ individual_sim_mat (e.g. `RDM_Group1.png`) /\n",
    "                ├─ initial_transportation_plan_name (e.g. `random`) /\n",
    "                        ├─  some figures(e.g. `RDM_Group1.png`) \n",
    "        \n",
    "``` \n",
    "\n",
    "- This folder structure will be automatically made in the process of GWOT optimization.\n",
    "- User is assumed to provide the names of the followings: `main_result_dir`,  `data_name`, and `pair_name`(defined by the two `representations.name`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an \"AlignRepresentations\" instance\n",
    "align_representation = AlignRepresentations(\n",
    "    config=config,\n",
    "    representations_list=representations,   \n",
    "\n",
    "    # histogram matching : this will adjust the histogram of target to that of source.\n",
    "    histogram_matching=False,\n",
    "\n",
    "    # metric : The metric for computing the distance between the embeddings. Please set the metric tha can be used in \"scipy.spatical.distance.cdist()\".\n",
    "    metric=\"cosine\", \n",
    "\n",
    "    # main_results_dir : folder or file name when saving the result\n",
    "    main_results_dir = \"../../results/\" + data_select,\n",
    "   \n",
    "    # data_name : Please rewrite this name if users want to use their own data.\n",
    "    data_name = data_select,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dissimilarity matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat_format = \"default\"\n",
    "\n",
    "visualize_config = VisualizationConfig(\n",
    "    figsize=(8, 6),\n",
    "    title_size = 15, \n",
    "    cmap=\"rocket_r\",\n",
    ")\n",
    "\n",
    "visualize_hist = VisualizationConfig(figsize=(8, 6), color='C0')\n",
    "\n",
    "sim_mat = align_representation.show_sim_mat(\n",
    "    sim_mat_format = sim_mat_format, \n",
    "    visualization_config = visualize_config,\n",
    "    visualization_config_hist = visualize_hist,\n",
    "    show_distribution=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reperesentation Similarity Aanalysis (RSA)\n",
    "This performs a conventional representation similarity analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### parameters for computing RSA\n",
    "# metric = \"pearson\" or \"spearman\" by scipy.stats\n",
    "# The result of RSA for each pair will be stored in align_representation.RSA_corr\n",
    "align_representation.RSA_get_corr(metric = \"pearson\")\n",
    "\n",
    "# print(align_representation.RSA_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GWOT is performed by appling the method `gw_alignment` to the instance of `AlignRepresentations` class.\n",
    "\n",
    "We show all the parameters to run GWOT computation as an example with THINGS or DNN dataset because these dataset have category information label.\n",
    "\n",
    "For the dataset of color, AllenBrain, and simulation (these doesn’t have the category information), we show how to do this in next cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the example to compute the GWOT for each pair for color, AllenBrain, and simulation datasets below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the computation has been completed and there is no need to recompute, set \"compute_OT\" to False. In this case, the previously calculated OT plans will be loaded.\n",
    "compute_OT = False\n",
    "\n",
    "### If the previous optimization data exists, you can delete it.\n",
    "# Setting delete_results=True will delete both the database and the directory where the results of the previous optimization are stored.\n",
    "# The code will prompt for confirmation before deleting all the results.\n",
    "delete_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mat_format = \"default\"\n",
    "\n",
    "visualize_config = VisualizationConfig(\n",
    "    show_figure=True,\n",
    "    figsize=(8, 8), \n",
    "    title_size = 15, \n",
    "    cmap=\"rocket_r\",\n",
    ")\n",
    "\n",
    "align_representation.gw_alignment(\n",
    "    compute_OT = compute_OT,\n",
    "    delete_results = delete_results,\n",
    "    return_data = False,\n",
    "    return_figure = True,\n",
    "    OT_format = sim_mat_format,\n",
    "    visualization_config = visualize_config,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Evaluation and Visualization\n",
    "Finally, you can evaluate and visualize the unsupervise alignment of GWOT.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show how the GWD was optimized\n",
    "`show_optimization_log` will make two figures to show both the relationships between epsilons (x-axis) and GWD (y-axis), and between accuracy (x-axis) and GWD (y-axis).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Show how the GWD was optimized (evaluation figure)\n",
    "# show both the relationships between epsilons and GWD, and between accuracy and GWD\n",
    "\n",
    "visualize_config = VisualizationConfig(\n",
    "    show_figure = True,\n",
    "    fig_ext='svg',\n",
    "    font='Arial',\n",
    "    cmap = 'viridis',\n",
    "    \n",
    "    plot_eps_log = eps_log,\n",
    ")\n",
    "\n",
    "\n",
    "align_representation.show_optimization_log(fig_dir=None, visualization_config=visualize_config) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the accuracy of the unsupervised alignment\n",
    "There are two ways to evaluate the accuracy.  \n",
    "1. Calculate the accuracy based on the OT plan. \n",
    "- For using this method, please set the parameter `eval_type = \"ot_plan\"` in \"calc_accuracy()\".\n",
    "  \n",
    "2. Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "-  For using this method, please set the parameter `eval_type = \"k_nearest\"` in \"calc_accuracy()\".\n",
    "\n",
    "For both cases, the accuracy evaluation criterion can be adjusted by considering \"top k\".  \n",
    "By setting \"top_k_list\", you can observe how the accuracy increases as the criterion is relaxed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the accuracy based on the OT plan. \n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"ot_plan\")\n",
    "align_representation.plot_accuracy(eval_type = \"ot_plan\", scatter = True)\n",
    "\n",
    "top_k_accuracy = align_representation.top_k_accuracy # you can get the dataframe directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the matching rate based on the k-nearest neighbors of the embeddings.\n",
    "align_representation.calc_accuracy(top_k_list = [1, 5, 10], eval_type = \"k_nearest\")\n",
    "align_representation.plot_accuracy(eval_type = \"k_nearest\", scatter = True)\n",
    "\n",
    "k_nearest_matching_rate = align_representation.k_nearest_matching_rate # you can get the dataframe directly "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the aligned embeddings\n",
    "Using optimized transportation plans, you can align the embeddings of each representation to a shared space in an unsupervised manner.  \n",
    "The `\"pivot\"` refers to the target embeddings space to which the other embeddings will be aligned.   \n",
    "You have the option to designate the `\"pivot\"` as one of the representations or the barycenter.  \n",
    "Please ensure that 'pair_number_list' includes all pairs between the pivot and the other Representations.  \n",
    "\n",
    "If you wish to utilize the barycenter, please make use of the method `AlignRepresentation.barycenter_alignment()`.  \n",
    "You can use it in the same manner as you did with `AlignRepresentation.gw_alignment()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_embedding = VisualizationConfig(\n",
    "    fig_ext=\"svg\",\n",
    "    figsize=(10, 10),\n",
    "    marker_size=80,\n",
    "    xlabel=\"PC1\",\n",
    "    ylabel=\"PC2\",\n",
    "    zlabel=\"PC3\",\n",
    "    legend_size=20,\n",
    "    font=\"Arial\",\n",
    "    color_hue=\"cool\",\n",
    "    cmap=\"cool\",\n",
    "    colorbar_label=\"short movies\",\n",
    "    colorbar_range=[0, len(emb)],\n",
    "    colorbar_shrink=0.8,\n",
    "    xlabel_size=20,\n",
    "    ylabel_size=20,\n",
    "    zlabel_size=20,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "align_representation.visualize_embedding(\n",
    "    dim=3, # the dimensionality of the space the points are embedded in. You can choose either 2 or 3.\n",
    "    pivot=0, # the number of one of the representations or the \"barycenter\".\n",
    "    method=\"PCA\",\n",
    "    visualization_config=visualization_embedding,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
